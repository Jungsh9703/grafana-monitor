#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Fetch OCI DB backups and store into MySQL with display_name/freeform_tags.
# - size_gbëŠ” ìƒì„±(STORED GENERATED) ì»¬ëŸ¼ì´ë¯€ë¡œ ì ˆëŒ€ ê°’ ì“°ì§€ ì•ŠìŒ (size_bytesë§Œ ì €ì¥)
# - manual_flag ì „ë©´ ì œê±°
# - ë™ê¸°í™” ëª¨ë“œ: ì´ë²ˆ ì‹¤í–‰ì—ì„œ ì¡°íšŒí•œ ë°±ì—…ë§Œ ë‚¨ê¸°ê³ , ë‚˜ë¨¸ì§€ëŠ” ì‚­ì œ
import os
import oci
import json
import logging
import pymysql
from datetime import datetime, timezone, timedelta
from oci.auth.signers import InstancePrincipalsSecurityTokenSigner
from dotenv import load_dotenv

logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] - [%(levelname)s] %(message)s in %(filename)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.FileHandler("/grafana_python/instance_principal_v/logs/dbcs_backup.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger("dbcs_backup")

# DB ì ‘ì† ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# ==================== CONFIG ====================
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASS = os.getenv("DB_PASS")
DB_NAME = os.getenv("DB_NAME")

# âœ… í…Œì´ë¸” ì´ë¦„ì€ ê³ ì •: dbcs_backup_status
TABLE_NAME = "dbcs_backup_status"

# âœ… ëª¨ë‹ˆí„°ë§í•  DBCS OCID ëª©ë¡ì€ .env ì˜ DBCS_OCIDS ì—ì„œ ì½ìŒ
# ì˜ˆ) DBCS_OCIDS="ocid1.database....,ocid1.database...."
DBCS_OCIDS_RAW = os.getenv("DBCS_OCIDS", "") or ""
DB_OCIDS = [x.strip() for x in DBCS_OCIDS_RAW.split(",") if x.strip()]

if not DB_OCIDS:
    logger.warning("DBCS_OCIDS í™˜ê²½ë³€ìˆ˜ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì²˜ë¦¬í•  ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    # ë°±ì—…ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì˜ë¯¸ê°€ ì—†ìœ¼ë‹ˆ ì¡°ìš©íˆ ì¢…ë£Œ
    exit(0)

LOOKBACK_DAYS = 14  # ìµœê·¼ Nì¼ë§Œ ë™ê¸°í™”. ì „ì²´ ë™ê¸°í™”ë¼ë©´ None

# ==================== HELPERS ====================
def connect_mysql():
    return pymysql.connect(
        host=DB_HOST,
        user=DB_USER,
        password=DB_PASS,
        database=DB_NAME,
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
        autocommit=True,
    )

def ensure_table_and_columns(cur):
    # manual_flag ì œê±°, size_gbëŠ” ìƒì„±ì»¬ëŸ¼(í…Œì´ë¸”ì— ì´ë¯¸ ì¡´ì¬í•´ë„ ì´ ì½”ë“œëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
    cur.execute(f"""
    CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
        id VARCHAR(200) PRIMARY KEY,
        db_name VARCHAR(100),
        type VARCHAR(20),
        time_started DATETIME NULL,
        time_ended DATETIME NULL,
        lifecycle_state VARCHAR(20) NOT NULL,
        size_bytes BIGINT NULL
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """)
    cur.execute(f"""
        SELECT COLUMN_NAME FROM information_schema.COLUMNS
        WHERE TABLE_SCHEMA=%s AND TABLE_NAME=%s
    """, (DB_NAME, TABLE_NAME))
    cols = {r["COLUMN_NAME"].lower() for r in cur.fetchall()}
    if "display_name" not in cols:
        cur.execute(f"ALTER TABLE {TABLE_NAME} ADD COLUMN display_name VARCHAR(255) NULL")
    if "freeform_tags" not in cols:
        cur.execute(f"ALTER TABLE {TABLE_NAME} ADD COLUMN freeform_tags JSON NULL")

def parse_size_fields(backup):
    # size_gbëŠ” DBì—ì„œ ìƒì„±ë˜ë¯€ë¡œ ì—¬ê¸°ì„  size_bytesë§Œ ê³„ì‚°
    for attr in ("size_in_bytes", "size_in_gbs", "size_in_mbs", "size_in_gigabytes"):
        v = getattr(backup, attr, None)
        if v is None:
            continue
        try:
            if attr.endswith("bytes"):
                return int(v)
            if attr.endswith("gbs") or attr.endswith("gigabytes"):
                return int(float(v) * 1024**3)
            if attr.endswith("mbs"):
                return int(float(v) * 1024**2)
        except Exception:
            pass
    return None

def to_dt(ts):
    if ts is None:
        return None
    if isinstance(ts, datetime):
        return ts.astimezone(timezone.utc).replace(tzinfo=None)
    try:
        return datetime.fromisoformat(str(ts).replace("Z", "+00:00")).astimezone(timezone.utc).replace(tzinfo=None)
    except Exception:
        return None

def upsert_backup(cur, row):
    # size_gb, manual_flag ì „ë©´ ë°°ì œ
    r = dict(row)
    r.pop("size_gb", None)

    cols = [
        "id", "db_name", "type", "time_started", "time_ended",
        "lifecycle_state", "size_bytes", "display_name", "freeform_tags"
    ]
    placeholders = [f"%({c})s" for c in cols]

    sql = f"""
    INSERT INTO {TABLE_NAME} ({", ".join(cols)})
    VALUES ({", ".join(placeholders)})
    ON DUPLICATE KEY UPDATE
      db_name=VALUES(db_name),
      type=VALUES(type),
      time_started=VALUES(time_started),
      time_ended=VALUES(time_ended),
      lifecycle_state=VALUES(lifecycle_state),
      size_bytes=VALUES(size_bytes),
      display_name=VALUES(display_name),
      freeform_tags=VALUES(freeform_tags)
    """
    cur.execute(sql, r)

# ----------------------------------
# Main
# ----------------------------------
def main():
    logger.info("DBCS ë°±ì—… ìˆ˜ì§‘ ì‹œì‘")

    try:
        conn = connect_mysql()
        cur = conn.cursor()
        logger.info("MySQL ì—°ê²° ì™„ë£Œ")
    except Exception as e:
        logger.error(f"MySQL ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

    try:
        ensure_table_and_columns(cur)
        logger.info("í…Œì´ë¸” ì´ˆê¸° ì…‹íŒ… ì™„ë£Œ")
    except Exception as e:
        logger.error(f"í…Œì´ë¸” ì´ˆê¸° ì…‹íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

    try:
        signer = InstancePrincipalsSecurityTokenSigner()
        region = os.getenv("OCI_REGION") or "ap-seoul-1"
        config = {"region": region}
        tenancy_id = os.getenv("TENANCY_OCID")

        db_client = oci.database.DatabaseClient(config, signer=signer)
        identity_client = oci.identity.IdentityClient(config, signer=signer)
        tenancy = identity_client.get_tenancy(tenancy_id).data
        logger.info("API ì—°ê²° ì™„ë£Œ")
    except Exception as e:
        logger.error(f"API ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

    lookback_ts = None
    if LOOKBACK_DAYS:
        lookback_ts = datetime.now(timezone.utc) - timedelta(days=LOOKBACK_DAYS)

    total = 0
    seen_ids = set()

    logger.info("DBCS ë°±ì—… ëª©ë¡ ìˆ˜ì§‘, ì €ì¥ ì¤‘")
    for db_ocid in DB_OCIDS:
        # ğŸ”¹ ì—¬ê¸°ì„œ ì‹¤ì œ DB ì´ë¦„/í‘œì‹œì´ë¦„ì„ OCIì—ì„œ ì¡°íšŒ
        try:
            db_info = db_client.get_database(db_ocid).data
            db_name = db_info.db_name or db_info.db_unique_name or db_info.display_name or db_ocid
        except Exception as e:
            logger.warning(f"DB ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨({db_ocid}) â†’ OCIDë¥¼ db_nameìœ¼ë¡œ ì‚¬ìš©: {e}")
            db_name = db_ocid

        next_page = None

        while True:
            kwargs = dict(database_id=db_ocid, limit=1000)
            if next_page:
                kwargs["page"] = next_page
            try:
                resp = db_client.list_backups(**kwargs)
            except Exception as e:
                logger.error(f"DBCS ë°±ì—… ëª©ë¡ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                raise

            backups = resp.data or []

            for b in backups:
                ts = getattr(b, "time_started", None)
                if lookback_ts and ts and ts < lookback_ts:
                    continue
                try:
                    size_bytes = parse_size_fields(b)
                except Exception as e:
                    logger.error(f"parse_size_fields() ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    raise

                row = {
                    "id": b.id,
                    "db_name": db_name,
                    "type": getattr(b, "type", None),
                    "time_started": to_dt(b.time_started),
                    "time_ended": to_dt(b.time_ended),
                    "lifecycle_state": getattr(b, "lifecycle_state", None),
                    "size_bytes": size_bytes,
                    "display_name": getattr(b, "display_name", None),
                    "freeform_tags": getattr(b, "freeform_tags", None)
                }

                try:
                    upsert_backup(cur, row)
                except Exception as e:
                    logger.error(f"upsert_backup() ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    raise

                seen_ids.add(row["id"])
                total += 1

            next_page = resp.headers.get("opc-next-page")
            if not next_page:
                break

    logger.info(f"DBCS ë°±ì—… ìˆ˜ì§‘ ì™„ë£Œ, ì´ {total}ê°œ")

    # -------------------
    # ë™ê¸°í™” ì‚­ì œ
    # -------------------
    logger.info("í…Œì´ë¸” ë™ê¸°í™” ì‘ì—… ì‹œì‘")
    try:
        if seen_ids:
            placeholders_id = ",".join(["%s"] * len(seen_ids))
            delete_sql = f"""
                DELETE FROM {TABLE_NAME}
                WHERE id NOT IN ({placeholders_id})
            """
            cur.execute(delete_sql, tuple(seen_ids))
            logger.info(f"ë™ê¸°í™”ë¡œ ì‚­ì œëœ row ìˆ˜: {cur.rowcount}")
        else:
            logger.info("ì´ë²ˆ ì‹¤í–‰ì—ì„œ ì¡°íšŒëœ ë°±ì—…ì´ ì—†ì–´ ë™ê¸°í™” ì‚­ì œ ìŠ¤í‚µ")

        cur.close()
        conn.close()
        logger.info("í…Œì´ë¸” ë™ê¸°í™” ì‘ì—… ì™„ë£Œ")
    except Exception as e:
        logger.error(f"í…Œì´ë¸” ë™ê¸°í™” ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


if __name__ == "__main__":
    main()

